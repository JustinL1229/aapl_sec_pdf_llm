{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"pymilvus[model]\"\n",
    "# !pip install ollama\n",
    "# !pip install langchain\n",
    "\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from pymilvus import MilvusClient, model\n",
    "\n",
    "from ollama import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split_documents(documents):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len\n",
    "    )\n",
    "\n",
    "    return splitter.split_documents(documents)\n",
    "\n",
    "def load_and_split_documents(file_path):\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    aapl_sec_filing_pages = loader.load()\n",
    "\n",
    "    split_filing = text_split_documents(aapl_sec_filing_pages)\n",
    "\n",
    "    document_content = [chunk.page_content for chunk in split_filing]\n",
    "    document_source_names = [(chunk.metadata['source'].split('/')[-1] + f\" (pg. {chunk.metadata['page']})\") for chunk in split_filing]\n",
    "\n",
    "    return document_content, document_source_names\n",
    "\n",
    "def create_load_collection(collection_name, document_content):\n",
    "    client = MilvusClient(f\"{collection_name}.db\")\n",
    "    embedding_fn = model.DefaultEmbeddingFunction()\n",
    "\n",
    "    if 'aapl_10k_collection' in client.list_collections():\n",
    "        print(f'Using existing db: {collection_name}')\n",
    "        client.load_collection(collection_name=f'{collection_name}_collection')\n",
    "    else:\n",
    "        print('Creating new vector db for documents...')\n",
    "\n",
    "        vectors = embedding_fn.encode_documents(document_content)\n",
    "        dims = embedding_fn.dim\n",
    "\n",
    "        client.create_collection(\n",
    "            collection_name=f\"{collection_name}_collection\",\n",
    "            dimension=dims\n",
    "        )\n",
    "\n",
    "        data = [\n",
    "            {\"id\": i, \"vector\": vectors[i], \"text\": document_content[i]}\n",
    "            for i in range(len(vectors))\n",
    "        ]\n",
    "\n",
    "        client.insert(collection_name=f\"{collection_name}_collection\", data=data)\n",
    "\n",
    "        print('Created db!')\n",
    "\n",
    "    return client\n",
    "\n",
    "def query_collection(questions, client, top_k=5):\n",
    "    embedding_fn = model.DefaultEmbeddingFunction()\n",
    "    query_vectors = embedding_fn.encode_queries(questions)\n",
    "\n",
    "    res = client.search(\n",
    "        collection_name=\"aapl_10k_collection\",\n",
    "        data=query_vectors,\n",
    "        limit=top_k,\n",
    "        output_fields=[\"id\", \"text\"],\n",
    "    )\n",
    "\n",
    "    return res\n",
    "\n",
    "def generate_llm_response(query_response, document_source_names, questions):\n",
    "    llm_reponses = []\n",
    "    q_num = 0\n",
    "    for res in query_response:\n",
    "        context = []\n",
    "        sources = []\n",
    "        for chunk in res:\n",
    "            sources.append(chunk['id'])\n",
    "            context.append(chunk['entity']['text'])\n",
    "        \n",
    "        PROMPT_TEMPATE = f\"\"\"\n",
    "    You are a financial analyst who has extensive knowledge of financial markets and \n",
    "    specialize in understanding SEC filings. You are only given the following chunks of context to \n",
    "    answer any questions:\n",
    "\n",
    "    {context}\"\"\"\n",
    "        \n",
    "\n",
    "        client = Client(host='http://localhost:11434')\n",
    "        response = client.chat(model='llama3', messages=[\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': PROMPT_TEMPATE,\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': questions[q_num],\n",
    "            }\n",
    "        ])\n",
    "\n",
    "        sources_str = \"\"\n",
    "\n",
    "        for idx in sources:\n",
    "            sources_str += document_source_names[idx] + ', '\n",
    "\n",
    "        output_str = \"Answer: \"\n",
    "\n",
    "        output_str += response['message']['content']\n",
    "\n",
    "        output_str += '\\nSources: ' + sources_str\n",
    "\n",
    "        llm_reponses.append(output_str)\n",
    "        q_num += 1\n",
    "\n",
    "    return llm_reponses\n",
    "\n",
    "def generate_completion(file_path, questions):\n",
    "    collection_name = 'aapl_10k'\n",
    "\n",
    "    print('Loading and splitting your doc...')\n",
    "    document_content, document_source_names = load_and_split_documents(file_path)\n",
    "    print('Doc loaded!\\n')\n",
    "\n",
    "    client = create_load_collection(collection_name, document_content)\n",
    "\n",
    "    print('Querying db...')\n",
    "    q_res = query_collection(questions, client)\n",
    "\n",
    "    print('Generating reponse...\\n')\n",
    "    llm_reponses = generate_llm_response(q_res, document_source_names, questions)\n",
    "\n",
    "    q_count = 1\n",
    "    for answr in llm_reponses:\n",
    "        print(f'------------------------------------------------Question {q_count}:------------------------------------------------\\n')\n",
    "        print(answr)\n",
    "        print('\\n')\n",
    "        q_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"What was Apple's net income this year?\",\n",
    "             \"Did Apple experience any significant losses?\",\n",
    "             \"Did Apple pay out any dividends this year?\"]\n",
    "\n",
    "generate_completion('INSERT PDF PATH HERE', questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
